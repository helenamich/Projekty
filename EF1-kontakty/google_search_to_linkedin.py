#!/usr/bin/env python3
"""
P≈ôevede Google search odkazy na p≈ô√≠m√© LinkedIn profily (jen kdy≈æ se shoduje firma).
1. Naƒçte FAIL - jaro 2025 - List 1.csv, najde ≈ô√°dky kde sloupec LinkedIn obsahuje google.com/search
2. Z URL vyt√°hne vyhled√°vac√≠ dotaz (parametr q) a firmu kontaktu (sloupec 7)
3. Zavol√° Google Custom Search API; z v√Ωsledk≈Ø vezme prvn√≠ odkaz na linkedin.com/in/.
   Je-li u kontaktu vyplnƒõn√° firma, bere se jen v√Ωsledek se shodnou firmou v titulku/snippetu;
   bez firmy se bere prvn√≠ LinkedIn odkaz
4. Aktualizuje kontakty_unified.csv (podle emailu) ‚Äì dopln√≠ LinkedIn profil

Pot≈ôeba: GOOGLE_API_KEY a GOOGLE_CSE_ID (Custom Search Engine).
Vytvo≈ôen√≠: https://programmablesearchengine.google.com/ (vyhled√°v√°n√≠ po cel√©m webu)
API kl√≠ƒç: https://console.cloud.google.com/ (Custom Search API)
"""

import csv
import os
import re
import sys
import time
import urllib.parse
import warnings
from pathlib import Path

warnings.filterwarnings("ignore", message=".*duckduckgo_search.*renamed.*")

try:
    import requests
except ImportError:
    requests = None
try:
    from duckduckgo_search import DDGS
except ImportError:
    DDGS = None

DIR = Path(__file__).resolve().parent
FAIL_CSV = DIR / "FAIL - jaro 2025 - List 1.csv"
UNIFIED_CSV = DIR / "kontakty_unified.csv"
LINKEDIN_COL_INDEX = 45
EMAIL_COL_INDEX = 4
FIRMA_COL_INDEX = 7


def get_query_from_google_url(url: str) -> str:
    """Z Google search URL vr√°t√≠ vyhled√°vac√≠ dotaz (parametr q)."""
    if not url or "google" not in url.lower():
        return ""
    try:
        parsed = urllib.parse.urlparse(url)
        params = urllib.parse.parse_qs(parsed.query)
        q = params.get("q", [""])[0]
        return (q or "").strip()
    except Exception:
        return ""


def normalize_firma_for_match(firma: str) -> str:
    """Pro porovn√°n√≠: mal√° p√≠smena, bez s.r.o. / a.s. atd., zkr√°cen√© mezery."""
    if not firma:
        return ""
    s = firma.lower().strip()
    for suffix in (" s.r.o.", " a.s.", " s.r.o", " a.s", ", s.r.o.", ", a.s."):
        s = s.replace(suffix, "")
    s = " ".join(s.split())
    return s


def firma_matches(firma: str, title: str, snippet: str) -> bool:
    """
    Pokud firma nen√≠ zadan√° ‚Üí True (bereme prvn√≠ v√Ωsledek).
    Pokud firma je zadan√° ‚Üí True jen kdy≈æ je firma (nebo jej√≠ v√Ωznamn√° ƒç√°st) v title nebo snippet.
    """
    if not firma or not firma.strip():
        return True
    if not (title or snippet):
        return False
    norm = normalize_firma_for_match(firma)
    if not norm:
        return True
    text = ((title or "") + " " + (snippet or "")).lower()
    words = [w for w in norm.split() if len(w) > 2]
    if not words:
        return norm in text
    return any(w in text for w in words) or norm in text


def first_linkedin_from_google_search(
    api_key: str, cse_id: str, query: str, firma: str
) -> str:
    """
    Zavol√° Google Custom Search API a vr√°t√≠ prvn√≠ odkaz na linkedin.com/in/,
    u kter√©ho se v titulku nebo snippetu shoduje firma.
    """
    if not query or not api_key or not cse_id:
        return ""
    url = "https://www.googleapis.com/customsearch/v1"
    params = {"key": api_key, "cx": cse_id, "q": query, "num": 10}
    try:
        r = requests.get(url, params=params, timeout=15)
        r.raise_for_status()
        data = r.json()
        for item in data.get("items", []):
            link = item.get("link", "")
            if not link or "linkedin.com/in/" not in link.lower():
                continue
            title = (item.get("title") or "").strip()
            snippet = (item.get("snippet") or "").strip()
            if not firma_matches(firma, title, snippet):
                continue
            link = link.split("?")[0].split("#")[0]
            if "linkedin.com" in link:
                return link
    except Exception as e:
        print(f"    API chyba: {e}")
    return ""


def first_linkedin_from_google_page(google_url: str) -> str:
    """
    Naƒçte p≈ô√≠mo str√°nku Google vyhled√°v√°n√≠ (URL z CSV) a z HTML vyt√°hne prvn√≠ odkaz na linkedin.com/in/.
    Bez API kl√≠ƒçe ‚Äì funguje, kdy≈æ Google vr√°t√≠ norm√°ln√≠ v√Ωsledky (ne captcha).
    """
    if not google_url or not requests:
        return ""
    # Google ƒçasto pou≈æ√≠v√° /url?q=SKUTECNA_URL ‚Äì hled√°me linkedin.com/in/ v href nebo v q=
    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml",
        "Accept-Language": "cs,en;q=0.9",
    }
    try:
        r = requests.get(google_url, headers=headers, timeout=15)
        r.raise_for_status()
        html = r.text
        # 1) Odkazy ve tvaru /url?q=https://www.linkedin.com/in/...
        for m in re.finditer(r'/url\?q=(https?%3A%2F%2F[^&"\']+)|/url\?q=(https?://[^&"\']+)', html):
            raw = m.group(1) or m.group(2) or ""
            if raw:
                url = urllib.parse.unquote(raw) if "%" in raw else raw
                if "linkedin.com/in/" in url.lower():
                    url = url.split("?")[0].split("#")[0]
                    if url.startswith("http"):
                        return url
        # 2) P≈ô√≠m√© href="https://www.linkedin.com/in/..."
        for m in re.finditer(r'href=["\'](https?://[^"\']*linkedin\.com/in/[^"\']+)["\']', html, re.I):
            url = m.group(1).split("?")[0].split("#")[0]
            if "linkedin.com" in url:
                return url
        # 3) Jak√Ωkoli v√Ωskyt https://...linkedin.com/in/...
        for m in re.finditer(r'https?://(?:www\.)?linkedin\.com/in/[^\s"\'<>\)]+', html, re.I):
            url = m.group(0).split("?")[0].split("#")[0]
            if "linkedin.com" in url:
                return url
    except Exception as e:
        print(f"    Chyba naƒçten√≠ str√°nky: {e}")
    return ""


def _extract_first_linkedin_from_html(html: str) -> str:
    """Z libovoln√©ho HTML vyt√°hne prvn√≠ odkaz na linkedin.com/in/."""
    if not html:
        return ""
    # Odkazy ve tvaru /url?q=...
    for m in re.finditer(r'/url\?q=(https?%3A%2F%2F[^&"\']+)|/url\?q=(https?://[^&"\']+)', html):
        raw = m.group(1) or m.group(2) or ""
        if raw:
            url = urllib.parse.unquote(raw) if "%" in raw else raw
            if "linkedin.com/in/" in url.lower():
                url = url.split("?")[0].split("#")[0]
                if url.startswith("http"):
                    return url
    # P≈ô√≠m√© href na LinkedIn
    for m in re.finditer(r'href=["\'](https?://[^"\']*linkedin\.com/in/[^"\']+)["\']', html, re.I):
        url = m.group(1).split("?")[0].split("#")[0]
        if "linkedin.com" in url:
            return url
    # Jak√Ωkoli v√Ωskyt URL
    for m in re.finditer(r'https?://(?:www\.)?linkedin\.com/in/[^\s"\'<>\)]+', html, re.I):
        url = m.group(0).split("?")[0].split("#")[0]
        if "linkedin.com" in url:
            return url
    return ""


def first_linkedin_from_duckduckgo_html(query: str) -> str:
    """Naƒçte DuckDuckGo HTML vyhled√°v√°n√≠ (bez API) a vr√°t√≠ prvn√≠ LinkedIn odkaz."""
    if not query or not requests:
        return ""
    url = "https://html.duckduckgo.com/html/"
    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml",
        "Accept-Language": "en-US,en;q=0.9",
    }
    try:
        r = requests.post(url, data={"q": query}, headers=headers, timeout=15)
        r.raise_for_status()
        return _extract_first_linkedin_from_html(r.text)
    except Exception as e:
        print(f"    DDG HTML: {e}")
    return ""


def first_linkedin_from_bing_page(query: str) -> str:
    """Naƒçte Bing vyhled√°v√°n√≠ (bez API) a vr√°t√≠ prvn√≠ LinkedIn odkaz."""
    if not query or not requests:
        return ""
    url = "https://www.bing.com/search"
    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml",
        "Accept-Language": "en-US,en;q=0.9",
    }
    try:
        r = requests.get(url, params={"q": query}, headers=headers, timeout=15)
        r.raise_for_status()
        return _extract_first_linkedin_from_html(r.text)
    except Exception as e:
        print(f"    Bing: {e}")
    return ""


def first_linkedin_from_duckduckgo(query: str, firma: str) -> str:
    """
    Vyhled√° dotaz p≈ôes DuckDuckGo (bez API kl√≠ƒçe) a vr√°t√≠ prvn√≠ odkaz na linkedin.com/in/,
    u kter√©ho se shoduje firma (pokud je zadan√°).
    """
    if not query or DDGS is None:
        return ""
    try:
        with DDGS() as ddgs:
            for r in ddgs.text(query, max_results=10):
                link = (r.get("href") or r.get("link") or "").strip()
                if not link or "linkedin.com/in/" not in link.lower():
                    continue
                title = (r.get("title") or "").strip()
                body = (r.get("body") or "").strip()
                if not firma_matches(firma, title, body):
                    continue
                link = link.split("?")[0].split("#")[0]
                if "linkedin.com" in link:
                    return link
    except Exception as e:
        print(f"    DuckDuckGo chyba: {e}")
    return ""


def main():
    api_key = os.getenv("GOOGLE_API_KEY")
    cse_id = os.getenv("GOOGLE_CSE_ID")
    use_google = api_key and cse_id
    if use_google and not requests:
        print("Nainstalujte: pip install requests")
        sys.exit(1)
    if not use_google:
        if not requests:
            print("Nainstalujte: pip install requests")
            sys.exit(1)
        print("Bez GOOGLE_API_KEY / GOOGLE_CSE_ID naƒçtu p≈ô√≠mo str√°nku Google (URL z CSV) a z n√≠ vyt√°hnu prvn√≠ LinkedIn odkaz.\n")

    # 1) Naƒç√≠st FAIL - jaro 2025: (email -> (query, firma)) kde sloupec 45 je Google search
    email_to_data = {}
    if not FAIL_CSV.exists():
        print(f"Soubor nenalezen: {FAIL_CSV}")
        sys.exit(1)
    with open(FAIL_CSV, "r", encoding="utf-8") as f:
        reader = csv.reader(f)
        for row in reader:
            if len(row) <= max(LINKEDIN_COL_INDEX, EMAIL_COL_INDEX, FIRMA_COL_INDEX):
                continue
            cell = (row[LINKEDIN_COL_INDEX] or "").strip()
            if "google.com/search" in cell.lower() or "google.cz/search" in cell.lower():
                email = (row[EMAIL_COL_INDEX] or "").strip().lower()
                firma = (row[FIRMA_COL_INDEX] or "").strip()
                if email:
                    q = get_query_from_google_url(cell)
                    if q:
                        email_to_data[email] = (q, firma, cell)  # cell = cel√° Google URL

    if not email_to_data:
        print("≈Ω√°dn√© Google search odkazy v FAIL - jaro 2025 (sloupec LinkedIn).")
        return

    print(f"Nalezeno {len(email_to_data)} kontakt≈Ø s Google search odkazem.")
    print("Dopln√≠m LinkedIn: u v√Ωsledk≈Ø s firmou jen p≈ôi shodƒõ firmy, bez firmy prvn√≠ odkaz.\n")

    # Limit pro test: --limit 30
    limit = None
    if "--limit" in sys.argv:
        idx = sys.argv.index("--limit")
        if idx + 1 < len(sys.argv):
            try:
                limit = int(sys.argv[idx + 1])
                email_to_data = dict(list(email_to_data.items())[:limit])
                print(f"(TEST: jen prvn√≠ch {limit} kontakt≈Ø)\n")
            except ValueError:
                pass

    # 2) Pro ka≈æd√Ω email spustit vyhled√°v√°n√≠, br√°t jen v√Ωsledek se shodnou firmou
    email_to_linkedin = {}
    rows = []
    headers = None
    with open(UNIFIED_CSV, "r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        headers = list(reader.fieldnames)
        rows = list(reader)

    for i, (email, data) in enumerate(email_to_data.items(), 1):
        query, firma, google_url = data[0], data[1], data[2]
        print(f"[{i}/{len(email_to_data)}] {query[:50]}‚Ä¶")
        if use_google:
            link = first_linkedin_from_google_search(api_key, cse_id, query, firma)
        else:
            link = first_linkedin_from_google_page(google_url)
            if not link:
                link = first_linkedin_from_duckduckgo_html(query)
            if not link:
                link = first_linkedin_from_bing_page(query)
        if link:
            email_to_linkedin[email] = link
            print(f"    ‚Üí LinkedIn: {link[:60]}‚Ä¶")
            for row in rows:
                if (row.get("Email") or "").strip().lower() == email and not (row.get("LinkedIn profil") or "").strip():
                    row["LinkedIn profil"] = link
                    break
        else:
            print("    ‚Üí ≈æ√°dn√Ω vhodn√Ω LinkedIn")
        time.sleep(0.3)
        # Pr≈Øbƒõ≈æn√© ukl√°d√°n√≠ ka≈æd√Ωch 10 kontakt≈Ø
        if i % 10 == 0 and headers and rows:
            with open(UNIFIED_CSV, "w", encoding="utf-8", newline="") as f:
                w = csv.DictWriter(f, fieldnames=headers)
                w.writeheader()
                w.writerows(rows)
            print(f"    üíæ ulo≈æeno ({len(email_to_linkedin)} doplnƒõno)")

    if not email_to_linkedin:
        print("\nNepoda≈ôilo se z√≠skat ≈æ√°dn√© LinkedIn URL.")
        return

    # 3) Fin√°ln√≠ z√°pis kontakty_unified.csv
    with open(UNIFIED_CSV, "w", encoding="utf-8", newline="") as f:
        w = csv.DictWriter(f, fieldnames=headers)
        w.writeheader()
        w.writerows(rows)

    print(f"\nHotovo. Doplnƒõno {len(email_to_linkedin)} LinkedIn profil≈Ø do kontakty_unified.csv.")


if __name__ == "__main__":
    main()
